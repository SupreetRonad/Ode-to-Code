{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of final Team_puthon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupreetRonad/Ode-to-Code/blob/main/puthon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQJ6K1jjCXE6",
        "outputId": "a10d180b-303b-4741-ffe8-547537baa900"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 0s (30.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13953 sha256=e2e16928cc59036b8f9a04555be55b48defa40ee9e1454644da559a1e71a7e94\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDN9uMWJRRJM"
      },
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbTImyeBBqIo"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkaQUdv6fPdk"
      },
      "source": [
        "#btained using ml model\n",
        "my_weights ={\n",
        "    'acute': 2,\n",
        "    'shortness': 4,\n",
        "    'fall': 4, 'died': 2, 'rash': 2, 'packed': 2, 'skin': 4, 'or': 0, 'condition': 6, 'ptx': 4, 'nosocomial': 2, 'rupture': 4, 'GPLA': 4, 'aspiration': 2, 'oversedation': 4, 'somnolent': 4, 'perforation': 4, 'surgery': 8, 'time': 10, 'nsicu': 4, 'hemorrhage': 4, 'heel': 6, 'sepsis': 4, 'consultations': 8, 'wound': 6, 'Past': 4, 'deep': 2, 'decubitus': 2, 'overload': 2, 'hyperkalemia': 4, 'pneumonia': 4, 'x-ray': 6, 'number': 6, 'failure': 4, 'diagnosis': 10, 'medicine': 2, 'decubiti': 2, 'hypoglycemia': 4, 'dissection': 6, 'room': 8, 'operating': 6, 'gender': 8, 'od': 2, 'ccu': 4, 'clostridium': 4, 'wet': 2, 'Health': 10, 'error': 0, 'mistakenly': 0, 'consult': 8, 'resuscitation': 4, 'reopen': 0, 'fell': 0, 'eruption': 4, 'Diet': 4, 'transferred': 0, 'next': 0, 'rbc': 4, 'delirium': 4, 'Investigation': 6, 'subtherapeutic': 6, 'tube': 4, 'icu': 6, 'transfer': 0, 'chest': 4, 'Attending': 4, 'infection': 6, 'required': 0, 'hyperglycemia': 4, 'dka': 2, 'vein': 6, 'distress': 4, 'signature': 10, 'admission': 10, 'reaction': 6, 'physician': 10, 'Date': 10, 'fluids': 6, 'family': 6, 'of': 0, 'Reason': 4, 'findings': 0, 'renal': 2, 'lethargic': 2, 'mistake': 0, 'complicated': 4, 'drug': 6, 'birth': 8, 'maternity': 4, '\\ufeffdischarge': 10, 'allergic': 6, 'sedated': 4, 'accident': 6, 'acquired': 0, 'after': 4, 'Wound': 6, 'post': 6, 'op': 6, 'pneumothorax': 4, 'supratherapeutic': 4, 'MLC': 2, 'ICU': 6, 'treatment': 10, 'drop': 0, 'agitation': 2, 'ulcer': 4, 'hospital': 10, 'respiratory': 4, 'desaturation': 4, 'dropped': 0, 'identifier': 0, 'ward': 10, 'laceration': 2, 'sugars': 4, 'overdose': 6, 'history': 8, 'death': 2, 'summary': 10, 'breath': 4, 'Method': 4, 'referral': 4, 'operation': 6, 'Unit': 4, 'volume': 0, 'hematoma': 4, 'contact': 8, 'status': 6, 'difficile': 2, 'age': 10, 'telemetry': 2, 'bed': 10, 'transfusion': 4, 'Patient': 10, 'blood': 6, 'hypoxia': 4, 'Provided': 0, 'hospitalization': 8, 'slipped': 0, 'postoperative': 6, 'FIR': 4, 'complication': 6, 'mental': 4, 'Address': 8, 'expired': 0, 'discontinued': 6, 'syncopy': 4, 'hypotension': 4, 'low': 2, 'Examination': 6, 'nonresponsive': 2, 'reopening': 2, 'pressure': 2, 'line': 2, 'unresponsive': 2, 'Consultant': 8, 'hallucinations': 4, 'micu': 4, 'the': 0, 'Instructions': 4, 'Operating': 6, 'Source': 4, 'fluid': 4, 'iv': 4, 'sore': 4, 'appointment': 6, 'medication': 8, 'admit': 8, 'name': 10, 'polypharmacy': 4, 'Procedures': 4, 'trauma': 4, 'hypoxemia': 4, 'accidentally': 4, 'RTA': 4, 'thrombosis': 4\n",
        "}\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjbyMWmbWQl0",
        "outputId": "3fd926a4-fe1c-4929-ede9-c78261db4cec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H8o_lTMX4fg"
      },
      "source": [
        "def returnSum(dict1,dict2):\n",
        "      \n",
        "     sum = 0\n",
        "     for i in dict1:\n",
        "           sum = sum + (dict1[i] *dict2[i])\n",
        "        \n",
        "     return sum"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka0tqVDIRUCZ"
      },
      "source": [
        "data_path='/content/drive/MyDrive/project'\n",
        "categories=os.listdir(data_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aW4ENgmZBqd"
      },
      "source": [
        "final=[]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjWcihyfXHAn",
        "outputId": "996f124e-6898-4e54-c3c2-5d92316d5ba0"
      },
      "source": [
        "for category in categories:\n",
        "  folder_path=os.path.join(data_path,category)\n",
        "  img_names=os.listdir(folder_path)\n",
        "        \n",
        "  for img_name in img_names:\n",
        "    img_path=os.path.join(folder_path,img_name)\n",
        "    extractedInformation = pytesseract.image_to_string(Image.open(img_path))\n",
        "    pdf_data=clean_text(extractedInformation).split()\n",
        "    my_file = open(r'/content/my_keywords.txt',\"r\")\n",
        "    k = my_file.read().split()\n",
        "    k = set(k)\n",
        "    dict_keywords={}\n",
        "        \n",
        "    for i in k:\n",
        "      dict_keywords[i]=0\n",
        "        \n",
        "    for i in dict_keywords:\n",
        "      if i in pdf_data:\n",
        "        dict_keywords[i]+=1\n",
        "    final.append(returnSum(dict_keywords,my_weights))\n",
        "print(final)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[108, 106, 12, 76, 110, 88, 28, 96, 68, 50, 88, 138, 64, 102, 22, 16, 10, 16, 12, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfFDgfSEabZG"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km =KMeans(n_clusters = 2)\n",
        "x=final\n",
        "y=[]\n",
        "for i in range(1,len(x)+1):\n",
        "  y.append(i)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIt7xItbadO7",
        "outputId": "8e4e6431-4f24-42d7-8d08-fa4d3fa7d85c"
      },
      "source": [
        "import numpy as np\n",
        "combined = np.vstack((x, y)).T\n",
        "km.fit(combined)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRGf3Y8-a_3k",
        "outputId": "81bd4642-b500-4188-dd8f-2206b15151b5"
      },
      "source": [
        "y_p = km.fit_predict(combined)\n",
        "print(y_p)\n",
        "print(x)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1]\n",
            "[108, 106, 12, 76, 110, 88, 28, 96, 68, 50, 88, 138, 64, 102, 22, 16, 10, 16, 12, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uav2LIY-bGI7"
      },
      "source": [
        "y_p = km.predict([[56,1]])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKNUszVvbirY",
        "outputId": "da207dd7-aaad-4a66-b0cf-ef8dfd40acc8"
      },
      "source": [
        "if y_p==[1]:\n",
        "  print('false')\n",
        "else :\n",
        "  print(\"true\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-bf_3lhb4lf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}